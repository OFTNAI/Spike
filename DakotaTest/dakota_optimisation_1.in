# DAKOTA INPUT FILE: dakota_pstudy.in for parallel Case 1 (Massively Serial)

environment,
	graphics
	tabular_data

# method,                                         
# #	conmin_frcg				
# 	efficient_global
# 	seed = 123456

method
	max_iterations = 10000
	max_function_evaluations = 200000
	coliny_ea
		population_size = 69
		fitness_type merit_function
		mutation_type offset_normal
		mutation_rate 1.0 				# Probability of a mutation
		crossover_type blend
		crossover_rate 0.5				# Probability of a crossover
		replacement_type chc = 23

model
	single


variables,					
#	continuous_design = 5			
#	cdv_initial_point   1.0      1.0      1.0     1.0     1.0
#	cdv_lower_bounds    0.50      0.10      0.10      0.10      0.10
#	cdv_upper_bounds    1.50      10.0      10.0      10.0      10.0 
#	cdv_descriptor      'gmax'      'tau_syn_const'      'conductanceConst_I2E_0'      'conductanceConst_I2E_1'      'conductanceConst_I2E_2'
	continuous_design = 5			
	cdv_lower_bounds    1.e-6      1.e-6      1.e-6      1.e-6      1.e-6 
	cdv_upper_bounds    1.e-2      1.e-2      1.e-2      1.e-2     1.e-2 

	cdv_descriptor      'G2E_biological_conductance_scaling_constant_lambda'      'E2E_biological_conductance_scaling_constant_lambda'      'E2I_biological_conductance_scaling_constant_lambda'      'I2E_biological_conductance_scaling_constant_lambda'      'I2I_biological_conductance_scaling_constant_lambda'


# Case 1 (Massively Serial): Run Dakota in parallel and launch M-1 serial
#         analysis jobs at once.  Do not specify any evaluation concurrency
#         (handled by parallel scheduler)
#         fork interface is recommended
interface,
	fork
# In an M processor allocation, by default Dakota will configure with
# a master scheduler with M-1 slave analysis processes.  Overriding
# this with evaluation_scheduling peer static will avoid this dedicated 
# master and use all M processors, but then each batch of M analyses will 
# have to complete before the next M are scheduled.  This may be useful if 
# all evaluations are known to take the same processor time:

#	  evaluation_scheduling peer static

# Dynamic scheduling may also be specified. In this mode, the first peer will
# attempt to act as both a master scheduler and an evaluation server. 
# Consequently, all M processors will be used as in the static case. Unlike the
# static case, evaluations are delegated to servers on the fly, making dynamic
# scheduling the better choice when evaluations may be of varying duration.

#         evaluation_scheduling peer dynamic

	  analysis_driver = 'single_simulation_driver'
	    parameters_file = 'params.in'
	    results_file = 'results.out'
	    file_tag
	    file_save

responses,
	objective_functions = 1
	sense = 'max'
	#nonlinear_inequality_constraints = 2
	no_gradients
	no_hessians
