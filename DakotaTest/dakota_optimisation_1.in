# DAKOTA INPUT FILE: dakota_pstudy.in for parallel Case 1 (Massively Serial)

environment,
	graphics
	tabular_data
	results_output

# method,                                         
# #	conmin_frcg				
# 	efficient_global
# 	seed = 123456

method
	max_iterations = 100000
	max_function_evaluations = 200000
	coliny_ea
		population_size = 100
		fitness_type merit_function
		mutation_type offset_normal
		mutation_rate 0.2 				# Probability of a mutation
		crossover_type blend
		crossover_rate 0.2				# Probability of a crossover
		replacement_type chc = 23
		solution_target = 100

model
	single


variables,					
	continuous_design = 4			
	cdv_lower_bounds    1.e-5	1.e-5      1.e-5      1.e-5
	cdv_upper_bounds    5.e-3	5.e-3      5.e-3      5.e-3

	cdv_descriptor      'E2E_FF_biological_conductance_scaling_constant_lambda' 'E2I_L_biological_conductance_scaling_constant_lambda'      'I2E_L_biological_conductance_scaling_constant_lambda'  'E2E_L_biological_conductance_scaling_constant_lambda'


# Case 1 (Massively Serial): Run Dakota in parallel and launch M-1 serial
#         analysis jobs at once.  Do not specify any evaluation concurrency
#         (handled by parallel scheduler)
#         fork interface is recommended
interface,
	fork
# In an M processor allocation, by default Dakota will configure with
# a master scheduler with M-1 slave analysis processes.  Overriding
# this with evaluation_scheduling peer static will avoid this dedicated 
# master and use all M processors, but then each batch of M analyses will 
# have to complete before the next M are scheduled.  This may be useful if 
# all evaluations are known to take the same processor time:

#	  evaluation_scheduling peer static

# Dynamic scheduling may also be specified. In this mode, the first peer will
# attempt to act as both a master scheduler and an evaluation server. 
# Consequently, all M processors will be used as in the static case. Unlike the
# static case, evaluations are delegated to servers on the fly, making dynamic
# scheduling the better choice when evaluations may be of varying duration.

#         evaluation_scheduling peer dynamic

	  analysis_driver = 'single_simulation_driver'
	    parameters_file = 'params.in'
	    results_file = 'results.out'
	    file_tag
	    file_save

responses,
	objective_functions = 1
	sense = 'max'
	#nonlinear_inequality_constraints = 2
	no_gradients
	no_hessians
